{
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "",
  "signature": "sha256:498acfa1bf1c2ffda18fa16202a732f138a83ad74a634ecb7c8c85ac20fcf73a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "News Group Text Classifier Part-2"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This Python code is an continuation of the R file available at "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!pip install --user sklearn #pip install --upgrade pip"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "News20 = pd.read_csv(\"D:/ISB/34-DataMining-2/Assignment/20News.csv\")\n",
      "News20.columns"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 1,
       "text": [
        "Index([u'Unnamed: 0', u'id', u'doc_collection', u'Topic_Names'], dtype='object')"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "News20.head(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>Unnamed: 0</th>\n",
        "      <th>id</th>\n",
        "      <th>doc_collection</th>\n",
        "      <th>Topic_Names</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>0</th>\n",
        "      <td>1</td>\n",
        "      <td>1</td>\n",
        "      <td>xref cantaloupe srv cs cmu alt atheism alt ath...</td>\n",
        "      <td>alt.atheism</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1</th>\n",
        "      <td>2</td>\n",
        "      <td>2</td>\n",
        "      <td>xref cantaloupe srv cs cmu alt atheism alt ath...</td>\n",
        "      <td>alt.atheism</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "   Unnamed: 0  id                                     doc_collection  \\\n",
        "0           1   1  xref cantaloupe srv cs cmu alt atheism alt ath...   \n",
        "1           2   2  xref cantaloupe srv cs cmu alt atheism alt ath...   \n",
        "\n",
        "   Topic_Names  \n",
        "0  alt.atheism  \n",
        "1  alt.atheism  "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Splitting up the data into training and Test*"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.model_selection import train_test_split\n",
      "News20_Train,News20_Test = train_test_split(News20,test_size=0.33, random_state=42)\n",
      "print \"Training Data:\",len(News20_Train),\"\\nTesting Data:\",len(News20_Test)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training Data: 13397 \n",
        "Testing Data: 6600\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Naive Bayes on Complete Corpus"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "vect = TfidfVectorizer()\n",
      "X_Train = vect.fit_transform(News20_Train.doc_collection)\n",
      "print X_Train.shape\n",
      "\n",
      "X_Test = vect.transform(News20_Test.doc_collection)\n",
      "print X_Test.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(13397, 93034)\n",
        "(6600, 93034)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.naive_bayes import MultinomialNB\n",
      "clf = MultinomialNB(alpha=30).fit(X_Train_tf_transformer,News20_Train.Topic_Names)\n",
      "\n",
      "predict_train = clf.predict(X_Train_tf_transformer)\n",
      "Accuracy_train = np.mean(predict_train == News20_Train.Topic_Names)*100\n",
      "print \"Accuracy of Training set:\",Accuracy_train\n",
      "\n",
      "predict_test = clf.predict(X_Test_tf_transformer)\n",
      "Accuracy_test = np.mean(predict_test == News20_Test.Topic_Names)*100\n",
      "print \"Accuracy of Test set:\",Accuracy_test"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of Training set: 92.5057848772\n",
        "Accuracy of Test set:"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 89.803030303\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Naive Bayes on top 5,000 words "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vect_5000 = TfidfVectorizer(max_features=5000)\n",
      "X_Train_5000 = vect_5000.fit_transform(News20_Train.doc_collection)\n",
      "print X_Train_5000.shape\n",
      "\n",
      "X_Test_5000 = vect_5000.transform(News20_Test.doc_collection)\n",
      "print X_Test_5000.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(13397, 5000)\n",
        "(6600, 5000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf5000 = MultinomialNB(alpha=30).fit(X_Train_5000,News20_Train.Topic_Names)\n",
      "predict_train5000 = clf5000.predict(X_Train_5000)\n",
      "Accuracy_train5000 = np.mean(predict_train5000 == News20_Train.Topic_Names)*100\n",
      "print \"Accuracy of Training set:\",Accuracy_train5000\n",
      "\n",
      "predict_test5000 = clf5000.predict(X_Test_5000)\n",
      "Accuracy_test5000 = np.mean(predict_test5000 == News20_Test.Topic_Names)*100\n",
      "print \"Accuracy of Test set:\",Accuracy_test5000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of Training set: 91.9907441965\n",
        "Accuracy of Test set: 90.6212121212\n"
       ]
      }
     ],
     "prompt_number": 162
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Naive Bayes on top 10,000 words "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "vect_10000 = TfidfVectorizer(max_features=10000)\n",
      "X_Train_10000 = vect_10000.fit_transform(News20_Train.doc_collection)\n",
      "print X_Train_10000.shape\n",
      "\n",
      "X_Test_10000 = vect_10000.transform(News20_Test.doc_collection)\n",
      "print X_Test_10000.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(13397, 10000)\n",
        "(6600, 10000)"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 163
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clf10000 = MultinomialNB(alpha=30).fit(X_Train_10000,News20_Train.Topic_Names)\n",
      "predict_train10000 = clf10000.predict(X_Train_10000)\n",
      "Accuracy_train10000 = np.mean(predict_train10000 == News20_Train.Topic_Names)*100\n",
      "print \"Accuracy of Training set:\",Accuracy_train10000\n",
      "\n",
      "predict_test10000 = clf10000.predict(X_Test_10000)\n",
      "Accuracy_test10000 = np.mean(predict_test10000 == News20_Test.Topic_Names)*100\n",
      "print \"Accuracy of Test set:\",Accuracy_test10000"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Accuracy of Training set: 92.4087482272\n",
        "Accuracy of Test set: 90.8484848485\n"
       ]
      }
     ],
     "prompt_number": 164
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "                                        IGNORE BELOW CODE\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.pipeline import Pipeline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text_clf = Pipeline([('vect', CountVectorizer()),\n",
      "                      ('tfidf', TfidfTransformer()),\n",
      "                      ('clf', MultinomialNB()),])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "text_clf.fit(News20.doc_collection,News20.Topic_Names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "docs_test = News20.doc_collection\n",
      "predicted = text_clf.predict(docs_test)\n",
      "np.mean(predicted == News20.Topic_Names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn.linear_model import SGDClassifier\n",
      "text_clf = Pipeline([('vect', CountVectorizer()),\n",
      "                     ('tfidf', TfidfTransformer()),\n",
      "                     ('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42,\n",
      "                                            #max_iter=5, tol=None\n",
      "                                          )),])\n",
      "text_clf.fit(News20.doc_collection, News20.Topic_Names)\n",
      "predicted = text_clf.predict(docs_test)\n",
      "np.mean(predicted == News20.Topic_Names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "#print(metrics.classification_report(News20.id, predicted,target_names=News20.Topic_Names))\n",
      "#help(metrics.classification_report)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(twenty.filenames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "from sklearn.datasets import fetch_20newsgroups\n",
      "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
      "print(\"No. of classes:\", len(twenty_train.target_names))\n",
      "twenty_train.target_names\n",
      "len(twenty_train.data)\n",
      "len(twenty_train.filenames)\n",
      "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n",
      "print(twenty_train.target_names[twenty_train.target[3]])\n",
      "twenty = fetch_20newsgroups(subset = 'all')\n",
      "len(twenty.data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print X_train_counts\n",
      "#print X_train_counts.shape\n",
      "#print Y_train_counts.shape\n",
      "#print X_test_counts.shape\n",
      "#print Y_test_counts.shape\n",
      "#X_train_counts"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print len(News20.Topic_Names)\n",
      "#print News20.Topic_Names.unique()\n",
      "#print len(News20.Topic_Names.unique())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print len(News20_Train.Topic_Names)\n",
      "#print News20_Train.Topic_Names.unique()\n",
      "#print len(News20_Train.Topic_Names.unique())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print len(News20_Test.Topic_Names)\n",
      "#print News20_Test.Topic_Names.unique()\n",
      "#print len(News20_Test.Topic_Names.unique())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import numpy as np\n",
      "#import pandas as pd\n",
      "#from nltk import sent_tokenize, word_tokenize, pos_tag\n",
      "#t = word_tokenize(News20.doc_collection[0]) #t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#X_train = count_vect.fit_transform(News20_Train.doc_collection)\n",
      "#Y_train = count_vect.fit_transform(News20_Train.Topic_Names)\n",
      "#X_test = count_vect.fit_transform(News20_Test.doc_collection)\n",
      "#Y_test = count_vect.fit_transform(News20_Test.Topic_Names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#News20.doc_collection[0]\n",
      "#print(\"\\n\".join(News20.doc_collection[0].split(\"\\n\")[:1]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print(News20.Topic_Names[:4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#from sklearn.feature_extraction.text import CountVectorizer\n",
      "#count_vect = CountVectorizer()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}